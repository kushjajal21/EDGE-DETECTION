{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.layers import Conv2D,Dense,LeakyReLU,Dropout,Reshape,Flatten,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "total = 1012224\n",
    "batches = total/bs\n",
    "alpha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6,kernel_size = 5,input_shape = (21,21,3),activation = 'relu'))\n",
    "model.add(Conv2D(12,kernel_size = 5,activation = 'relu'))\n",
    "model.add(Conv2D(16,kernel_size = 3,activation = 'relu'))\n",
    "model.add(Conv2D(32,kernel_size = 3,activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 17, 17, 6)         456       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 13, 13, 12)        1812      \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 11, 11, 16)        1744      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 9, 9, 32)          4640      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 2593      \n",
      "=================================================================\n",
      "Total params: 11,245\n",
      "Trainable params: 11,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"inputs.h5\",\"r\") as f:\n",
    "    data = np.asarray(f['data'])\n",
    "    label = np.asarray(f['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1012224, 21, 21, 3) (1012224, 1)\n"
     ]
    }
   ],
   "source": [
    "label = label.reshape(total,1)\n",
    "print(data.shape,label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "data,label = shuffle(data,label)\n",
    "\n",
    "Loss = []\n",
    "Acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################\n",
      "Epoch:1\n",
      "Batch 1000 Completed\n",
      "Loss:0.6528079267144203\n",
      "Accuracy:0.6267734375\n",
      "Batch 2000 Completed\n",
      "Loss:0.6393630838692188\n",
      "Accuracy:0.64533984375\n",
      "Batch 3000 Completed\n",
      "Loss:0.6316034662127494\n",
      "Accuracy:0.6525885416666667\n",
      "Batch 4000 Completed\n",
      "Loss:0.6248975602388382\n",
      "Accuracy:0.65816796875\n",
      "Batch 5000 Completed\n",
      "Loss:0.6199541270136834\n",
      "Accuracy:0.6621\n",
      "Batch 6000 Completed\n",
      "Loss:0.6164310218294462\n",
      "Accuracy:0.6647213541666667\n",
      "1908/1908 [==============================] - 1s 468us/step\n",
      "[0.5960351602336396, 0.6792452828939106]\n",
      "################\n",
      "Epoch:2\n",
      "Batch 1000 Completed\n",
      "Loss:0.5945323075652122\n",
      "Accuracy:0.681015625\n",
      "Batch 2000 Completed\n",
      "Loss:0.5921256026178598\n",
      "Accuracy:0.68361328125\n",
      "Batch 3000 Completed\n",
      "Loss:0.5911314261257649\n",
      "Accuracy:0.6844869791666667\n",
      "Batch 4000 Completed\n",
      "Loss:0.5900675772204995\n",
      "Accuracy:0.685224609375\n",
      "Batch 5000 Completed\n",
      "Loss:0.589257286965847\n",
      "Accuracy:0.6858359375\n",
      "Batch 6000 Completed\n",
      "Loss:0.5888444518943627\n",
      "Accuracy:0.6860872395833333\n",
      "1908/1908 [==============================] - 0s 181us/step\n",
      "[0.5769669913395896, 0.7002096433559554]\n",
      "################\n",
      "Epoch:3\n",
      "Batch 1000 Completed\n",
      "Loss:0.5825333648324013\n",
      "Accuracy:0.6909609375\n",
      "Batch 2000 Completed\n",
      "Loss:0.5833211139887571\n",
      "Accuracy:0.6911796875\n",
      "Batch 3000 Completed\n",
      "Loss:0.5831923990249633\n",
      "Accuracy:0.6912578125\n",
      "Batch 4000 Completed\n",
      "Loss:0.58257932305336\n",
      "Accuracy:0.69158984375\n",
      "Batch 5000 Completed\n",
      "Loss:0.5820989120900631\n",
      "Accuracy:0.6920828125\n",
      "Batch 6000 Completed\n",
      "Loss:0.581217147871852\n",
      "Accuracy:0.692953125\n",
      "1908/1908 [==============================] - 0s 168us/step\n",
      "[0.5849451586385443, 0.6912997901064795]\n",
      "################\n",
      "Epoch:4\n",
      "Batch 1000 Completed\n",
      "Loss:0.5779417170286179\n",
      "Accuracy:0.6963203125\n",
      "Batch 2000 Completed\n",
      "Loss:0.5770627631992101\n",
      "Accuracy:0.69683203125\n",
      "Batch 3000 Completed\n",
      "Loss:0.5779555845359962\n",
      "Accuracy:0.6959609375\n",
      "Batch 4000 Completed\n",
      "Loss:0.5772482247725129\n",
      "Accuracy:0.696421875\n",
      "Batch 5000 Completed\n",
      "Loss:0.5770537148296833\n",
      "Accuracy:0.6967375\n",
      "Batch 6000 Completed\n",
      "Loss:0.5769679716974497\n",
      "Accuracy:0.69688671875\n",
      "1908/1908 [==============================] - 0s 111us/step\n",
      "[0.56800367647247, 0.7054507337526206]\n",
      "################\n",
      "Epoch:5\n",
      "Batch 1000 Completed\n",
      "Loss:0.5755182705521583\n",
      "Accuracy:0.697984375\n",
      "Batch 2000 Completed\n",
      "Loss:0.5742701372802258\n",
      "Accuracy:0.6990859375\n",
      "Batch 3000 Completed\n",
      "Loss:0.5739584352870782\n",
      "Accuracy:0.6995390625\n",
      "Batch 4000 Completed\n",
      "Loss:0.5736051765754819\n",
      "Accuracy:0.699724609375\n",
      "Batch 5000 Completed\n",
      "Loss:0.5731777558028698\n",
      "Accuracy:0.700184375\n",
      "Batch 6000 Completed\n",
      "Loss:0.5731658053894838\n",
      "Accuracy:0.70028125\n",
      "1908/1908 [==============================] - 0s 177us/step\n",
      "[0.586188597624157, 0.6912997904813515]\n",
      "################\n",
      "Epoch:6\n",
      "Batch 1000 Completed\n",
      "Loss:0.571116162866354\n",
      "Accuracy:0.7013984375\n",
      "Batch 2000 Completed\n",
      "Loss:0.5707315754145383\n",
      "Accuracy:0.70251953125\n",
      "Batch 3000 Completed\n",
      "Loss:0.569970368941625\n",
      "Accuracy:0.7029166666666666\n",
      "Batch 4000 Completed\n",
      "Loss:0.5698295772448182\n",
      "Accuracy:0.70287890625\n",
      "Batch 5000 Completed\n",
      "Loss:0.5698634395122528\n",
      "Accuracy:0.7028234375\n",
      "Batch 6000 Completed\n",
      "Loss:0.5695581956207753\n",
      "Accuracy:0.70297265625\n",
      "1908/1908 [==============================] - 0s 172us/step\n",
      "[0.5766200214561926, 0.6912997903563941]\n",
      "################\n",
      "Epoch:7\n",
      "Batch 1000 Completed\n",
      "Loss:0.57008755210042\n",
      "Accuracy:0.70234375\n",
      "Batch 2000 Completed\n",
      "Loss:0.5684368031919003\n",
      "Accuracy:0.7034296875\n",
      "Batch 3000 Completed\n",
      "Loss:0.5678906233708064\n",
      "Accuracy:0.7039270833333333\n",
      "Batch 4000 Completed\n",
      "Loss:0.5677379690632224\n",
      "Accuracy:0.7041328125\n",
      "Batch 5000 Completed\n",
      "Loss:0.5672256947636605\n",
      "Accuracy:0.7046546875\n",
      "Batch 6000 Completed\n",
      "Loss:0.5668258840243021\n",
      "Accuracy:0.7049453125\n",
      "1908/1908 [==============================] - 0s 125us/step\n",
      "[0.5624259539120352, 0.7075471699362781]\n",
      "################\n",
      "Epoch:8\n",
      "Batch 1000 Completed\n",
      "Loss:0.5652588723599911\n",
      "Accuracy:0.7073984375\n",
      "Batch 2000 Completed\n",
      "Loss:0.5646571224331856\n",
      "Accuracy:0.7065625\n",
      "Batch 3000 Completed\n",
      "Loss:0.5642935074269771\n",
      "Accuracy:0.7064869791666667\n",
      "Batch 4000 Completed\n",
      "Loss:0.56440324793756\n",
      "Accuracy:0.706375\n",
      "Batch 5000 Completed\n",
      "Loss:0.5648561203539372\n",
      "Accuracy:0.7060375\n",
      "Batch 6000 Completed\n",
      "Loss:0.5646734450260799\n",
      "Accuracy:0.7062434895833334\n",
      "1908/1908 [==============================] - 0s 166us/step\n",
      "[0.5617526760891048, 0.7054507336276632]\n",
      "################\n",
      "Epoch:9\n",
      "Batch 1000 Completed\n",
      "Loss:0.5629685904383659\n",
      "Accuracy:0.7077890625\n",
      "Batch 2000 Completed\n",
      "Loss:0.5633889792859554\n",
      "Accuracy:0.70733984375\n",
      "Batch 3000 Completed\n",
      "Loss:0.5633399045467377\n",
      "Accuracy:0.7070885416666667\n",
      "Batch 4000 Completed\n",
      "Loss:0.5632099817395211\n",
      "Accuracy:0.707162109375\n",
      "Batch 5000 Completed\n",
      "Loss:0.5629587398052216\n",
      "Accuracy:0.70745625\n",
      "Batch 6000 Completed\n",
      "Loss:0.5626291710635026\n",
      "Accuracy:0.7076888020833333\n",
      "1908/1908 [==============================] - 0s 147us/step\n",
      "[0.5537846920625219, 0.7201257859136073]\n",
      "################\n",
      "Epoch:10\n",
      "Batch 1000 Completed\n",
      "Loss:0.562443800419569\n",
      "Accuracy:0.7076875\n",
      "Batch 2000 Completed\n",
      "Loss:0.5615080407261849\n",
      "Accuracy:0.7081328125\n",
      "Batch 3000 Completed\n",
      "Loss:0.5615382167796293\n",
      "Accuracy:0.7082395833333334\n",
      "Batch 4000 Completed\n",
      "Loss:0.5612847615107894\n",
      "Accuracy:0.708587890625\n",
      "Batch 5000 Completed\n",
      "Loss:0.5609801762461663\n",
      "Accuracy:0.708821875\n",
      "Batch 6000 Completed\n",
      "Loss:0.560481743251284\n",
      "Accuracy:0.7090755208333334\n",
      "1908/1908 [==============================] - 0s 213us/step\n",
      "[0.5656451871560054, 0.7033542976939203]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data,label = shuffle(data,label)\n",
    "    print(\"################\")\n",
    "    print(\"Epoch:\"+str(epoch+1))\n",
    "    for i in range(int(batches)-1908):\n",
    "        x_batch = data[bs*i:bs*(i+1),:,:,:]\n",
    "        y_batch = label[bs*i:bs*(i+1),:]\n",
    "        x_batch = x_batch/255\n",
    "        \n",
    "        l,a = model.train_on_batch(x_batch,y_batch)\n",
    "        loss += l\n",
    "        acc += a\n",
    "        \n",
    "        if i % 1000 == 999:\n",
    "            print(\"Batch \"+str(i+1)+\" Completed\")\n",
    "            print(\"Loss:\"+str(loss/(i+1)))    \n",
    "            print(\"Accuracy:\"+str(acc/(i+1)))\n",
    "    print(model.evaluate(data[6000:7908,:,:,:]/255,label[6000:7908,:]))\n",
    "    Loss.append(loss/(batches-1908))\n",
    "    Acc.append(acc/(batches-1908))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908/1908 [==============================] - 0s 215us/step\n",
      "[0.5656451871560054, 0.7033542976939203]\n",
      "[0.6164310218294462, 0.5888444518943627, 0.581217147871852, 0.5769679716974497, 0.5731658053894838, 0.5695581956207753, 0.5668258840243021, 0.5646734450260799, 0.5626291710635026, 0.560481743251284]\n",
      "[0.6647213541666667, 0.6860872395833333, 0.692953125, 0.69688671875, 0.70028125, 0.70297265625, 0.7049453125, 0.7062434895833334, 0.7076888020833333, 0.7090755208333334]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(data[6000:7908,:,:,:]/255,label[6000:7908,:]))\n",
    "print(Loss)\n",
    "print(Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
